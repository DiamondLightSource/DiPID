import torch
from torch import optim, nn, Tensor
from torch.utils.data import DataLoader
from peak_detector.sslm.model import SSLModel
from peak_detector.sslm.utils.evaluator import SSLEvaluator
from peak_detector.tlm.utils.trainer import TLMTrainer

# from tlm.model.trainer import ModelTrainer #imports failing, copy class into file instead??
import loss_utils.centres as utils
from typing import Any
import numpy as np
import matplotlib.pyplot as plt


# one image loop based on https://github.com/osmond332/Spatial_Guided_Self_Supervised_Clustering/blob/main/demo_final.py


class SSLTrainer(TLMTrainer):
    def __init__(
        self,
        model: SSLModel,
        train_dl: DataLoader,
        test_dl: DataLoader,
        num_epochs: int,
        save_freq: int,
        eval_freq: int,
        threshold=0.5,
        stepsizes=[0.0, 1.0, 1.0],
    ) -> None:
        """Load in the model and the data, and set up tools needed for training

        Args:
            model (SSLModel): self-supervised CNN model
            train_dl (DataLoader): dataset and labels for training
            test_dl (DataLoader): dataset and labels for testing / evaluation
            num_epochs (int): maximum number of epochs to train for
            save_freq (int): number of epochs after which model weights are saved
            eval_freq (int): number of epochs after which the model performance is evaluated
            threshold (float, optional): confidence threshold for accepting a prediction during evaluation. Defaults to 0.5.
            stepsizes (list, optional): weights to assign to each loss function when training, in the order context consistency, sparse spatial, cross entropy. Defaults to [0.0, 1.0, 1.0].
        """
        super(SSLTrainer, self).__init__(
            None, train_dl, test_dl, num_epochs, save_freq, eval_freq, threshold  # type: ignore
        )

        # override values from tlm trainer
        self.model = model
        self.model = self.model.to(self.device)

        self.folder = "peak_detector/sslm/training_outputs"
        self.label_colours = np.random.randint(255, size=(100, 3))

        self.cc_stepsize, self.ce_stepsize, self.ss_stepsize = stepsizes
        self.ce_loss_fn = nn.CrossEntropyLoss().to(self.device)
        self.ss_x_loss_fn = nn.L1Loss().to(self.device)
        self.ss_y_loss_fn = nn.L1Loss().to(self.device)

        self.W = self.model.width
        self.H = self.model.height
        self.C = self.model.out_channels
        self.target_map_x = torch.zeros(self.W - 1, self.H, self.C).to(self.device)
        self.target_map_y = torch.zeros(self.W, self.H - 1, self.C).to(self.device)

    def create_optimiser(self, learning_rate) -> optim.SGD:
        return optim.SGD(self.model.parameters(), lr=learning_rate, momentum=0.9)

    def create_lr_scheduler(self) -> None:
        """TO DO: investigate change in performance if a scheduler is used"""
        return None

    def calc_losses(self, pred_image: Tensor) -> Tensor:
        """Calculate the three different types of loss used in training

        Args:
            pred_image (Tensor): output tensor generated by the model

        Returns:
            Tensor: total loss for this prediction
        """
        cc_loss = torch.zeros(1).requires_grad_(True).to(self.device)

        epsilon = 1e-6
        # Calculate the context-based consistency loss for each predicted channel
        all_centres = utils.get_centres(pred_image, self.device, self.C)
        for channel in range(self.C):
            out_map = (pred_image[channel, :, :] + epsilon).to(self.device)
            k = out_map.sum().to(self.device)
            out_map_pdf = out_map / k
            centre_x, centre_y = all_centres[channel]
            var_x, var_y = self.get_variance(out_map_pdf, centre_x, centre_y)
            var_x = var_x.to(self.device)
            var_y = var_y.to(self.device)
            cc_loss = cc_loss + abs(var_x / k) + abs(var_y / k)
        # reshape to useful dimensions
        pred = pred_image.permute(1, 2, 0).contiguous().view(-1, self.C)
        out_map = pred_image.reshape((self.W, self.H, self.C))

        # Calculate horizontal and vertical sparse spatial losses
        x_map = out_map[1:, :, :] - out_map[:-1, :, :]
        y_map = out_map[:, 1:, :] - out_map[:, :-1, :]
        x_map = x_map.to(self.device)
        y_map = y_map.to(self.device)

        x_loss: Tensor = self.ss_x_loss_fn(x_map, self.target_map_x)
        y_loss: Tensor = self.ss_y_loss_fn(y_map, self.target_map_y)
        ss_loss = x_loss + y_loss

        max_values, target_idxs = torch.max(pred, 1)
        img_target = target_idxs.detach().cpu().numpy()

        # Combine all losses
        cc_loss = self.cc_stepsize * cc_loss
        ce_loss = self.ce_stepsize * self.ce_loss_fn(pred, target_idxs)
        ss_loss = ss_loss * self.ss_stepsize
        loss = cc_loss + ce_loss + ss_loss
        # print(
        #     f"losses: {loss.item()} | cc/ce/ss: {cc_loss.item()} + {ce_loss} + {ss_loss}"
        # )

        return loss

    def train_one_epoch(self, epoch_no: int, save_imgs=False) -> None:
        """Complete one training cycle and calculate test losses

        Args:
            epoch_no (int): number of the current loop being executed
            save_imgs (bool, optional): whether to save the predicted results as png. Defaults to False.
        """
        self.model.train()
        if epoch_no == self.num_epochs:
            save_imgs = True

        # could be generalised with the DataParallel functionality to train on multiple GPUs
        for batch_imgs, batch_labels in self.train_loader:
            batch_imgs = [b.to(self.device) for b in batch_imgs]

            batch_loss = 0
            for count, image in enumerate(batch_imgs):
                # calculate losses:
                self.optimiser.zero_grad()
                pred: Tensor = self.model(image.unsqueeze(dim=0))[0]

                loss = self.calc_losses(pred)

                batch_loss += loss.item()
                loss.backward()
                self.optimiser.step()

                if save_imgs:
                    nxs_no = batch_labels["nxs_no"][count]
                    img_no = batch_labels["img_no"][count]

                    output = pred.permute(1, 2, 0).contiguous().view(-1, self.C)

                    ignore, target = torch.max(output, 1)

                    img_target = target.data.cpu().numpy()
                    img_target_rgb = np.array(
                        [self.label_colours[channel % self.C] for channel in img_target]
                    )
                    img_target_rgb = img_target_rgb.reshape((195, 487, 3)).astype(
                        np.uint8
                    )
                    print(f"Saving to {self.folder}/{nxs_no}-{img_no}")
                    plt.imsave(f"{self.folder}/{nxs_no}-{img_no}.png", img_target_rgb)

            self.train_losses.append(batch_loss)
        self.avg_train_losses.append(np.average(self.train_losses))

        if epoch_no % self.save_freq == 0:
            filename = f"{self.folder}/{epoch_no}.torch"
            torch.save(self.model.state_dict(), filename)
            self.last_save_no = epoch_no
            print(f"State saved at epoch {epoch_no}")

    @torch.no_grad()
    def calc_test_losses(self) -> None:
        """Calculate losses on the test dataset"""
        for batch_imgs, batch_labels in self.test_loader:
            # batch = batch[0]
            # batch = batch.unsqueeze(dim=1)
            batch_loss = 0
            for image in batch_imgs:
                pred = self.model(image.unsqueeze(dim=0).to(self.device))[0]
                batch_loss += self.calc_losses(pred).item()
            self.test_losses.append(batch_loss)
        self.avg_test_losses.append(np.average(self.test_losses))

    @torch.no_grad()
    def evaluate(self, state_dict_path: str) -> None:
        """Evaluate model performance on the test dataset

        Args:
            state_dict_path (str): file containing the weights to be evaluated
        """
        eval = SSLEvaluator(
            self.test_loader,
            state_dict_path,
            self.C,
            self.device,
            self.threshold,
        )
        self.mean_ious.append(eval.compute_mean_iou())
        print(f"Mean AP on test dataset: {self.mean_ious[-1]}")

    @torch.no_grad()
    def histogram(self, state_dict_path: str, hist_file: str):
        """Create histogram of IoU scores for each image in the test dataset

        Args:
            state_dict_path (str): file containing model weights to be evaluated
            hist_file (str): file to save the histogram to
        """
        eval = SSLEvaluator(
            self.test_loader,
            state_dict_path,
            self.C,
            self.device,
            self.threshold,
        )
        mean = eval.make_histogram(hist_file)
        self.mean_ious.append(mean)
        print(f"Mean AP on test dataset: {self.mean_ious[-1]}")

    def get_variance(
        self, map: Tensor, centre_x: Tensor, centre_y: Tensor
    ) -> tuple[Tensor, Tensor]:
        """Calculate the variance of a prediction about its cluster centre

        Args:
            map (Tensor): prediction by the model in one channel
            centre_x (Tensor): x co-ordinate of the cluster centre
            centre_y (Tensor): y co-ordinate of the cluster centre

        Returns:
            tuple[Tensor, Tensor]: variance in x and y
        """
        x_map, y_map = utils.get_coordinate_tensors(self.W, self.H, self.device)
        x_map = torch.transpose(x_map, 1, 0)
        y_map = torch.transpose(y_map, 1, 0)

        var_x_map = (x_map - centre_x) ** 2
        var_y_map = (y_map - centre_y) ** 2

        var_x = (map * var_x_map).sum()
        var_y = (map * var_y_map).sum()
        return var_x, var_y
